{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CART算法，又能回归又能分类\n",
    "# 是一种树结构\n",
    "# 连续变量是回归，有限个离散变量是分类\n",
    "# 这个只做二分切割\n",
    "# 就是递归的构造二叉树\n",
    "# cart剪枝其实就是为了交叉验证用\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入训练数据集，停止计算的条件，停止计算的条件是节点中样本个数小于预定阈值，或样本属于同一类，或没有更多特征\n",
    "# 计算传入数据的Gini指数，基尼指数越大，不确定性就越大\n",
    "def calcGini(dataSet):\n",
    "    #dataSet=dataSet[list(dataSet[:,0]=='青年')]\n",
    "    # 获得y中分类标签的唯一值\n",
    "    y_lables = np.unique(dataSet[: , -1])\n",
    "    y_counts=len(dataSet) # y总数据条数\n",
    "    y_p={}             # y中每一个分类的概率，字典初始化为空，y分类数是不定的，按字典存储更方便取值\n",
    "    gini=1.0\n",
    "    for y_lable in y_lables:\n",
    "        y_p[y_lable]=len(dataSet[dataSet[:, -1]==y_lable])/y_counts  # y中每一个分类的概率（其实就是频率）\n",
    "        gini-=y_p[y_lable]**2\n",
    "    return gini\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分数据集,每一列x找到一个最优特征进行划分\n",
    "def splitDataSet(dataSet, i, value,types=1):\n",
    "    #dataSet[list(dataSet[:,0]!='青年')]\n",
    "    if types==1: # 使用此列特征中的value进行划分数据\n",
    "        subDataSet=dataSet[list(dataSet[:,i]==value)]  # 按照数据x第i列==value即可判断，不需要像《机器学习实战》书里写的那么复杂\n",
    "        subDataSet = np.array(subDataSet)           # 强制转换为array类型\n",
    "    elif types==2: # 使用此列特征中的不等于value的进行划分数据\n",
    "        subDataSet=dataSet[list(dataSet[:,i]!=value)]  # 按照数据x第i列==value即可判断，不需要像《机器学习实战》书里写的那么复杂\n",
    "        subDataSet = np.array(subDataSet)           # 强制转换为array类型\n",
    "    return subDataSet ,len(subDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历所有x特征列中的所有特征，寻找最优划分特征\n",
    "# 计算Gini指数，选择最好的特征划分数据集，即返回最佳特征下标及传入数据集各列的Gini指数\n",
    "def chooseBestFeature(dataSet,types='Gini'):\n",
    "   numTotal=dataSet.shape[0]              # 记录本数据集总条数\n",
    "   numFeatures = len(dataSet[0]) - 1      # 最后一列为y，计算x特征列数\n",
    "   bestFeature = -1                       # 初始化参数，记录最优特征列i，下标从0开始\n",
    "   columnFeaGini={}                       # 初始化参数，记录每一列x的每一种特征的基尼 Gini(D,A)\n",
    "   for i in range(numFeatures):           # 遍历所有x特征列\n",
    "       # i=2\n",
    "       prob = {}                          # 按x列计算各个分类的概率\n",
    "       featList = list(dataSet[:,i])      # 取这一列x中所有数据，转换为list类型\n",
    "       prob=dict(Counter(featList))       # 使用Counter函数计算这一列x各特征数量\n",
    "       for value in prob.keys():          # 循环这一列的特征，计算H(D|A)\n",
    "           # value='是'\n",
    "           feaGini = 0.0\n",
    "           bestFlag = 1.00001  # 对某一列x中，会出现x=是，y=是的特殊情况，这种情况下按“是”、“否”切分数据得到的Gini都一样，设置此参数将所有特征都乘以一个比1大一点点的值，但按某特征划分Gini为0时，设置为1\n",
    "           subDataSet1,sublen1 = splitDataSet(dataSet, i, value, 1)  # 获取切分后的数据\n",
    "           subDataSet2,sublen2 = splitDataSet(dataSet, i, value, 2)\n",
    "           if (sublen1/numTotal) * calcGini(subDataSet1)==0: # 判断按此特征划分Gini值是否为0（全部为一类）\n",
    "               bestFlag = 1 \n",
    "           feaGini += (sublen1/numTotal) * calcGini(subDataSet1) + (sublen2/numTotal) * calcGini(subDataSet2)\n",
    "           columnFeaGini['%d_%s'%(i,value)]=feaGini*bestFlag\n",
    "   bestFeature=min(columnFeaGini,key=columnFeaGini.get) # 找到最小的Gini指数益对应的数据列\n",
    "   return bestFeature,columnFeaGini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet,features,types='Gini'):\n",
    "    \"\"\"\n",
    "    输入：训练数据集D，特征集A，阈值ε\n",
    "    输出：决策树T\n",
    "    \"\"\"\n",
    "    y_lables = np.unique(dataSet[: , -1])\n",
    "\n",
    "    #1、如果数据集D中的所有实例都属于同一类label（Ck），则T为单节点树，并将类label（Ck）作为该结点的类标记，返回T\n",
    "    if len(set(y_lables)) == 1:\n",
    "        return y_lables[0]\n",
    "    \n",
    "    #2、若特征集A=空，则T为单节点，并将数据集D中实例树最大的类label（Ck）作为该节点的类标记，返回T\n",
    "    if len(dataSet[0]) == 1:\n",
    "        labelCount = {}\n",
    "        labelCount=dict(Counter(y_lables))\n",
    "        return max(labelCount,key=labelCount.get)\n",
    "    \n",
    "    #3、否则，按CART算法就计算特征集A中各特征对数据集D的Gini，选择Gini指数最小的特征bestFeature（Ag）进行划分\n",
    "    bestFeature,columnFeaGini=chooseBestFeature(dataSet,types) \n",
    "    \n",
    "    bestFeatureLable = features[int(bestFeature.split('_')[0])]    #最佳特征\n",
    "    decisionTree = {bestFeatureLable:{}}        #构建树，以Gini指数最小的特征bestFeature为子节点\n",
    "    del(features[int(bestFeature.split('_')[0])])                  #该特征已最为子节点使用，则删除，以便接下来继续构建子树\n",
    "    \n",
    "    #使用beatFeature进行划分，划分产生2各节点，成树T，返回T\n",
    "    y_lables_split=dataSet[list(dataSet[:,int(bestFeature.split('_')[0])]==bestFeature.split('_')[1])][:,-1] # 获取按此划分后y数据列表\n",
    "    y_lables_grp=dict(Counter(y_lables_split)) # 统计最优划分应该属于哪个i叶子节点“是”、“否”\n",
    "    y_leaf=max(y_lables_grp,key=y_lables_grp.get) # 获得划分后出现概率最大的y分类\n",
    "    decisionTree[bestFeatureLable][bestFeature.split('_')[1]]= y_leaf # 设定左枝叶子值\n",
    "    \n",
    "    #4、删除此最优划分数据x列，使用其他x列数据，递归地调用步1-3，得到子树Ti，返回Ti\n",
    "    dataSetNew= np.delete(dataSet,int(bestFeature.split('_')[0]),axis=1) # 删除此最优划分x列，使用剩余的x列进行数据划分\n",
    "    subFeatures = features[:]\n",
    "    # 判断右枝类型，划分后的左右枝“是”、“否”是不一定的，所以这里进行判断\n",
    "    y1=y_lables[0] # CART树y只能有2个分类\n",
    "    y2=y_lables[1] \n",
    "    if y_leaf==y1:\n",
    "        decisionTree[bestFeatureLable][y2]= {}\n",
    "        decisionTree[bestFeatureLable][y2] = createTree(dataSetNew, subFeatures,types)\n",
    "    elif y_leaf==y2:\n",
    "        decisionTree[bestFeatureLable][y1]= {}\n",
    "        decisionTree[bestFeatureLable][y1] = createTree(dataSetNew, subFeatures,types)\n",
    "    return decisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 除了上面的分类树，还有回归树，这就不打了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
