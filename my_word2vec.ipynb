{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 词袋法可以对文本内容相似性进行度量\n",
    "# 但是对于两段内容其实差不多但是用的词不一样的就不行了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# nltk主要是进行词性标注的，找到相似性也无法针对具体词汇之间的含义进行度量\n",
    "# 所以为了找到词汇之间相似度的关系，我们将词汇表示向量化\n",
    "# 这个其实就可以根据前面三个单词，预测最后一个单词，构成监督学习"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "X, y = news.data, news.target\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk, re\n",
    "# 这nltk扩展包下的还挺麻烦"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#定义一个函数名为news_to_sentences\n",
    "# 将每条新闻中的句子逐一剥离出来，并返回一个句子的列表\n",
    "def news_to_sentences(news):\n",
    "    news_text=BeautifulSoup(news).get_text()\n",
    "    tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences=tokenizer.tokenize(news_text)\n",
    "    sentences=[]\n",
    "    for sent in raw_sentences:\n",
    "        sentences.append(re.sub('[^a-zA-Z]',' ',sent.lower().strip()).split())\n",
    "    return sentences\n",
    "sentences=[]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#将长篇新闻文本中的句子剥离出来，用于训练\n",
    "for x in X:\n",
    "    sentences+=news_to_sentences(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "#配置词向量的维度\n",
    "num_features=300\n",
    "#保证被考虑的词汇的频度\n",
    "min_word_count=20\n",
    "#设定并行化训练使用CPU计算核心的数量，多核可用\n",
    "num_workers=2\n",
    "#定义训练词向量的上下文窗口大小\n",
    "context=5\n",
    "downsampling=1e-3#1e-3第一个是数字1，不是字母l\n",
    "\n",
    "from gensim.models import word2vec\n",
    "\n",
    "#训练词向量模型\n",
    "model=word2vec.Word2Vec(sentences,workers=num_workers,\\\n",
    "                       size=num_features,min_count=min_word_count,\\\n",
    "                       window=context,sample=downsampling)\n",
    "\n",
    "#这个设定代表当前训练好的词向量为最终版，也可以加快模型的训练速度\n",
    "model.init_sims(replace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "d:\\ai\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n  \n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "[('afternoon', 0.8176407814025879),\n ('weekend', 0.7953598499298096),\n ('evening', 0.7908556461334229),\n ('saturday', 0.7033148407936096),\n ('night', 0.702003002166748),\n ('friday', 0.6876775026321411),\n ('sunday', 0.685408353805542),\n ('newspaper', 0.6757447123527527),\n ('week', 0.6473132371902466),\n ('summer', 0.6368684768676758)]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "#利用训练好的模型，寻找训练文本中与morning最相关的10个词汇\n",
    "model.most_similar('morning')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "d:\\ai\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n  \"\"\"Entry point for launching an IPython kernel.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "[('mail', 0.7279140949249268),\n ('contact', 0.675162672996521),\n ('request', 0.6692183017730713),\n ('address', 0.6512033939361572),\n ('snail', 0.64162278175354),\n ('send', 0.6322551965713501),\n ('subscription', 0.6288837194442749),\n ('listserv', 0.6252148151397705),\n ('sas', 0.6230258941650391),\n ('replies', 0.6117781400680542)]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "model.most_similar('email')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 在不用语言学词典的情况下，词向量技术可以借助上下文来找到词汇之间的相似性\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}